import sys, os
sys.path.append('.')
from contrastive_learning.Models.Frame import Contrastive_Frame, train
from contrastive_learning.Models.Data import Contrastive_Dataset, MIRBS_Dataset
from torch.utils.data import DataLoader
import torch
import torch.optim as optim
from Models.Models import Ete_Model, Moco_Model
from contrastive_learning.Models.Feature_transform import HighDimBatchAugment
from utils import search_files_in_directory
from multiprocessing import cpu_count
from contrastive_learning.Models.Scheduler import WarmupLinearSchedule
TRAIN_DICT = {
    "ETE": Ete_Model,
    "MOCO": Moco_Model
}
DATASET_DICT = {
    1: Contrastive_Dataset,
    2: MIRBS_Dataset
}
# å¯é€‰ç”¨çš„æ¨¡å‹å¦‚ä¸‹ï¼š
# 'SRACN' 'Common_1DCNN' 'Common_2DCNN' 'Common_3DCNN' "Res_3D_18Net" "Res_3D_34Net" "Res_3D_50Net" 'SSRN' 
# 'HybridSN' 'Vgg16' 'MobileNetV1' 'MobileNetV2' 'ResNet18' 'ResNet34' 'ResNet50' 'spec_transformer'

encoder_model_name = 'spec_transformer'
config_model_name = "Test"  # æ¨¡å‹åç§°
TRAIN_MODE = "ETE" # ETE or MOCO è®­ç»ƒæ–¹å¼é€‰æ‹©
DATA_MANAGE_MODE = 2 # æ•°æ®ç®¡ç†æ–¹å¼ï¼Œ1ä¸ºæ ¹æ®è£å‰ªçš„æ ·æœ¬è¿›è¡Œè®­ç»ƒï¼Œ2ä¸ºæ ¹æ®é€‰æ‹©çš„å½±åƒè‡ªåŠ¨è®­ç»ƒ
images_dir = r'c:\Users\85002\Desktop\111' # æ•°æ®é›†


if_full_cpu = True # æ˜¯å¦å…¨è´Ÿè·cpu
epochs = 100  # epoch, å®é™…è®­ç»ƒè½®æ•°ä¸º epochs + warm_up_epochs
batch = 1024  # batch
init_lr = 1e-4  # lr
min_lr = 1e-6 # æœ€ä½å­¦ä¹ ç‡
warm_up_epochs = 10  # é¢„çƒ­epochæ•°
ck_pth = None

K = 65536
m = 0.999
T = 0.07
patch_size = 17 # DATA_MANAGE_MODE = 2æ—¶éœ€æŒ‡å®šè¯¥
MUITITHREADING_MODE = True
USE_DATA_PARALLEL = True # æ˜¯å¦ä½¿ç”¨DataParallelè¿›è¡Œå¤šæ˜¾å¡è®­ç»ƒ

"""ç‰¹å¾å›¾ç»˜åˆ¶ç›¸å…³å‚æ•°"""
FEATURE_MAP_LAYER_NAMES = None # æŒ‡å®šéœ€è¦ç»˜åˆ¶ç‰¹å¾å›¾çš„å±‚åï¼Œä½¿ç”¨åˆ—è¡¨å½¢å¼ï¼Œä¾‹å¦‚ ['encoder','layer1.0.conv1']ï¼Œä¸ºNoneåˆ™ç»˜åˆ¶æ‰€æœ‰å±‚
FEATURE_MAP_NUM = 36 # æ¯ä¸ªå±‚ç»˜åˆ¶çš„ç‰¹å¾å›¾æ•°é‡
FEATURE_MAP_INTERVAL = 10 # æ¯éš”å¤šå°‘ä¸ªepochç»˜åˆ¶ä¸€æ¬¡ç‰¹å¾å›¾
if __name__ == '__main__':  
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")  # æ˜¾å¡è®¾ç½®
    gpu_count = torch.cuda.device_count()
    if gpu_count < 2:
        USE_DATA_PARALLEL = False
    dataloader_num_workers = cpu_count() // 4 # æ ¹æ®cpuæ ¸å¿ƒæ•°è‡ªåŠ¨å†³å®šnum_workersæ•°é‡
    dataloader_num_workers = dataloader_num_workers if MUITITHREADING_MODE else 0
    # é…ç½®dataloader
    image_lists = search_files_in_directory(images_dir, ('tif', 'dat'))
    dataset = DATASET_DICT[DATA_MANAGE_MODE](image_lists, patch_size=patch_size, multith_mode=MUITITHREADING_MODE)
    model = TRAIN_DICT[TRAIN_MODE](encoder_model_name=encoder_model_name, in_shape=dataset.data_shape, K=K, m=m, T=T)  # æ¨¡å‹å®ä¾‹åŒ–
    print(f"ğŸ” PyTorch Version: {torch.__version__}")
    print(f"ğŸ¯ Image shape: {dataset.data_shape}")
    optimizer = optim.Adam(model.parameters(), lr=init_lr)  # ä¼˜åŒ–å™¨
    scheduler = WarmupLinearSchedule(optimizer, warmup_steps=warm_up_epochs, t_total=epochs+warm_up_epochs, min_lr=min_lr)

    augment = HighDimBatchAugment(spectral_mask_prob=0, spectral_mask_p=0.25, band_dropout_prob=0.5, bands_dropout_p=0.25)
    dataloader = DataLoader(dataset, batch_size=batch, shuffle=True, pin_memory=True, num_workers=dataloader_num_workers,
                            persistent_workers=MUITITHREADING_MODE and dataloader_num_workers > 0, drop_last=True)  # æ•°æ®è¿­ä»£å™¨

    frame = Contrastive_Frame(augment=augment, 
                           model_name=f'{encoder_model_name}_{config_model_name}', 
                           epochs=epochs+warm_up_epochs, 
                           min_lr=min_lr, 
                           device=device, 
                           if_full_cpu=if_full_cpu,
                           feature_map_layer_n=FEATURE_MAP_LAYER_NAMES,
                           feature_map_num=FEATURE_MAP_NUM,
                           feature_map_interval=FEATURE_MAP_INTERVAL,
                           use_data_parallel=USE_DATA_PARALLEL)
    
    train(frame=frame,
          model=model,
          optimizer=optimizer,
          scheduler=scheduler,
          dataloader=dataloader,
          ck_pth=ck_pth, 
        )