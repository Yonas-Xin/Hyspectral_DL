"""å°†å¤§å¹…é«˜å…‰è°±å½±åƒè¿›è¡Œåˆ†å—çš„æ»‘çª—é¢„æµ‹ï¼Œé¿å…å ç”¨å¤§é‡æ˜¾å­˜
é¢„æµ‹ç»“æœæ˜¯ä¸€ä¸ªäºŒç»´çŸ©é˜µï¼Œ255ä»£è¡¨èƒŒæ™¯, å…¶ä½™å€¼ä»£è¡¨é¢„æµ‹çš„åœ°ç‰©ç±»åˆ«, æœ€å¤šé¢„æµ‹256ç±»ï¼ˆåŒ…æ‹¬èƒŒæ™¯ï¼‰"""
import sys, os
sys.path.append('.')
from cnn_model.Models.Data import Predict_Dataset
from torch.utils.data import DataLoader
import utils
from core import Hyperspectral_Image
import numpy as np
import torch
from tqdm import tqdm
import matplotlib.pyplot as plt
from datetime import datetime
from multiprocessing import cpu_count
import matplotlib
import re
matplotlib.use('Agg')

output_path = 'SRACN_PRE.tif'
batch = 128
input_data = r"C:\Users\85002\OneDrive - cugb.edu.cn\é¡¹ç›®æ•°æ®\å¼ å·é“€èµ„æº\ZY_result\Image\research_area1.dat"
model_pth = r'cnn_model\_results\Common_1DCNN_Test_Patch17_202511241428_ID9iuaw3s6bopxyubfbtdog\Common_1DCNN_Test_Patch17_202511241428_ID9iuaw3s6bopxyubfbtdog_best.pt'  # æ¨¡å‹è·¯å¾„
MUTITHREADING_MODE = False # æ˜¯å¦ä½¿ç”¨å¤šçº¿ç¨‹åŠ é€Ÿæ•°æ®åŠ è½½, å®æµ‹Fasleæ—¶é€Ÿåº¦æ›´å¿«ï¼Œæ ¹æ®æƒ…å†µä½¿ç”¨
DRAW_RGB = True # æ˜¯å¦ç»˜åˆ¶é¢„æµ‹è¿‡ç¨‹ä¸­çš„rgbå›¾åƒ
rgb_combine = (25,15,5) #(29,19,9) # ç»˜åˆ¶å›¾åƒæ—¶çš„rgbç»„åˆï¼Œä»1å¼€å§‹, å¦‚æœæ— æ•ˆåˆ™ä½¿ç”¨ç¬¬ä¸€ä¸ªæ³¢æ®µ, å›¾åƒå¤ªå¤§æ—¶ä¸€å®šç¨‹åº¦ä¸Šä¼šå½±å“é€Ÿåº¦
image_block_size = 512 # åˆ†å—é¢„æµ‹æ—¶æ¯ä¸ªå¤§å—çš„å¤§å°ï¼Œè¶Šå¤§è¶Šå ç”¨å†…å­˜ï¼Œä½†é¢„æµ‹é€Ÿåº¦è¶Šå¿«
if __name__ == '__main__':
    patch_size = re.search(r'Patch(\d+)', os.path.basename(model_pth))
    if patch_size is None:
        raise ValueError("Patch size not found in model path! Please ensure the model path contains 'PatchXX' indicating the patch size.")
    patch_size = int(patch_size.group(1))
    print(f"ğŸ¯ The Patch Size: {patch_size}")
    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
    left_top = int(patch_size / 2 - 1) if patch_size % 2 == 0 else int(patch_size // 2)
    current_time = datetime.now().strftime("%Y%m%d%H%M")  # è®°å½•ç³»ç»Ÿæ—¶é—´
    output_path = f"{output_path[:-4]}_{current_time}.tif"
    img = Hyperspectral_Image()
    img.init(input_data, rgb=rgb_combine)
    predict_whole_map = np.empty((img.rows,img.cols), dtype=np.uint8) + 255 # èƒŒæ™¯å€¼ä¸º-1
    model = torch.load(model_pth, weights_only=False, map_location=device)
    model.to(device)
    model.eval()
    if DRAW_RGB:
        out_png = f"{output_path[:-4]}.png"
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))
        ax1.imshow(img.ori_img)
        ax1.axis('off')
        ax2.axis('off')

    num_workers = cpu_count() // 4 if MUTITHREADING_MODE else 0
    dataset = Predict_Dataset(patch_size)
    dataloader = DataLoader(dataset, batch_size=batch, shuffle=False, num_workers=num_workers, 
                            pin_memory=True if num_workers > 0 else False) # å®æµ‹è¿™é‡Œnumworkerå˜å¤šä¸ä¼šåŠ å¿«é€Ÿç‡ï¼Œåè€Œä¼šå› ä¸ºåŠ è½½çº¿ç¨‹æ‹–æ…¢é€Ÿåº¦
    with torch.no_grad():
        for image_block, background_mask, i, j in img.image_block_iter(block_size=image_block_size, patch_size=patch_size):
            rows, cols = background_mask.shape
            predict_map = np.zeros((rows, cols), dtype=np.uint8) + 255 # åˆå§‹åŒ–ä¸€ä¸ªç©ºçš„é¢„æµ‹mapï¼Œ-1ä»£è¡¨èƒŒæ™¯å€¼
            if np.any(background_mask == True): # å¦‚æœ
                idx = 0
                dataset.update_data(image_block, background_mask) # æ›´æ–°datasetåè°ƒç”¨dataloaderä¼šé‡æ–°å¯åŠ¨è¿›ç¨‹
                predict_data = torch.empty(len(dataset), dtype=torch.uint8, device=device) # é¢„åˆ†é…å†…å­˜ï¼Œç”¨æ¥å‚¨å­˜é¢„æµ‹ç»“æœ
                for data in tqdm(dataloader, total=len(dataloader), desc=f'Block Predicting'):
                    batch = data.shape[0]
                    data = data.to(device)
                    outputs = model(data)
                    _, predicted = torch.max(outputs, 1)
                    predict_data[idx:idx + batch, ] = predicted
                    idx += batch
                predict_map[background_mask] = predict_data.cpu().numpy() if predict_data.device.type == 'cuda' else predict_data.numpy() # å°†é¢„æµ‹ç»“æœå¡«å…¥å¯¹åº”ä½ç½®
                predict_whole_map[i:i+rows, j:j+cols] = predict_map # å°†é¢„æµ‹ç»“æœå¡«å…¥æ•´ä½“é¢„æµ‹çŸ©é˜µ
                img.save_tif(output_path, predict_whole_map, nodata=255) # ä¿å­˜ä¸ºtifæ–‡ä»¶

                # ä¸‹é¢ä¿å­˜é¢„æµ‹è¿‡ç¨‹ä¸­çš„å›¾åƒ
                if DRAW_RGB:
                    map = utils.label_to_rgb(predict_whole_map, background_value=255)
                    ax2.imshow(map)
                    fig.savefig(out_png, bbox_inches='tight', dpi=150)