import sys, os
sys.path.append('.')
from cnn_model.Models.Data import Predict_Dataset
from torch.utils.data import DataLoader
import utils
from core import Hyperspectral_Image
import numpy as np
import torch
from tqdm import tqdm
import matplotlib.pyplot as plt
from datetime import datetime
from multiprocessing import cpu_count
import matplotlib
import re
matplotlib.use('Agg')

output_path = 'SRACN_PRE.tif'
batch = 256
input_data = r""
model_pth = r'.\model.pt'  # æ¨¡å‹è·¯å¾„
MUTITHREADING_MODE = False # æ˜¯å¦ä½¿ç”¨å¤šçº¿ç¨‹åŠ é€Ÿæ•°æ®åŠ è½½, å®æµ‹Fasleæ—¶é€Ÿåº¦æ›´å¿«ï¼Œæ ¹æ®æƒ…å†µä½¿ç”¨
rgb_combine = (25,15,5) #(29,19,9) # ç»˜åˆ¶å›¾åƒæ—¶çš„rgbç»„åˆï¼Œä»1å¼€å§‹, å¦‚æœæ— æ•ˆåˆ™ä½¿ç”¨ç¬¬ä¸€ä¸ªæ³¢æ®µ, å›¾åƒå¤ªå¤§æ—¶ä¸€å®šç¨‹åº¦ä¸Šä¼šå½±å“é€Ÿåº¦
image_block_size = 512 # åˆ†å—é¢„æµ‹æ—¶æ¯ä¸ªå¤§å—çš„å¤§å°ï¼Œè¶Šå¤§è¶Šå ç”¨å†…å­˜ï¼Œä½†é¢„æµ‹é€Ÿåº¦è¶Šå¿«

if __name__ == '__main__':
    patch_size = re.search(r'Patch(\d+)', os.path.basename(model_pth))
    if patch_size is None:
        raise ValueError("Patch size not found in model path! Please ensure the model path contains 'PatchXX' indicating the patch size.")
    patch_size = int(patch_size.group(1))
    print(f"ğŸ¯ The Patch Size: {patch_size}")
    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
    left_top = int(patch_size / 2 - 1) if patch_size % 2 == 0 else int(patch_size // 2)
    current_time = datetime.now().strftime("%Y%m%d%H%M")  # è®°å½•ç³»ç»Ÿæ—¶é—´
    output_path = f"{output_path[:-4]}_{current_time}.tif"
    img = Hyperspectral_Image()
    img.init(input_data, rgb=rgb_combine)
    predict_whole_map = np.empty((img.rows,img.cols), dtype=np.uint8) + 255 # èƒŒæ™¯å€¼ä¸º-1

    # è®¾ç½®ç»˜åˆ¶å›¾åƒçš„å‚æ•°
    out_png = f"{output_path[:-4]}.png"
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))
    global_rgb_vis = utils.label_to_rgb(predict_whole_map, background_value=255) 
    ax1.imshow(img.ori_img)
    ax1.axis('off')
    pred_imshow_obj = ax2.imshow(global_rgb_vis) # è·å– image object å¼•ç”¨ï¼Œåç»­é€šè¿‡å®ƒæ›´æ–°æ•°æ®
    ax2.axis('off')
    plt.tight_layout()

    model = torch.load(model_pth, weights_only=False, map_location=device)
    model.to(device) # ç§»åŠ¨æ¨¡å‹åˆ°æŒ‡å®šè®¾å¤‡
    model.eval() # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    num_workers = cpu_count() // 4 if MUTITHREADING_MODE else 0
    dataset = Predict_Dataset(patch_size)
    dataloader = DataLoader(dataset, batch_size=batch, shuffle=False, num_workers=num_workers, 
                            pin_memory=True if num_workers > 0 else False) # å®æµ‹è¿™é‡Œnumworkerå˜å¤šä¸ä¼šåŠ å¿«é€Ÿç‡ï¼Œåè€Œä¼šå› ä¸ºåŠ è½½çº¿ç¨‹æ‹–æ…¢é€Ÿåº¦
    with torch.no_grad():
        for image_block, background_mask, i, j in img.image_block_iter(block_size=image_block_size, patch_size=patch_size):
            rows, cols = background_mask.shape
            predict_map = np.zeros((rows, cols), dtype=np.uint8) + 255 # åˆå§‹åŒ–ä¸€ä¸ªç©ºçš„é¢„æµ‹mapï¼Œ-1ä»£è¡¨èƒŒæ™¯å€¼
            if np.any(background_mask): # å¦‚æœ
                idx = 0
                dataset.update_data(image_block, background_mask) # æ›´æ–°datasetåè°ƒç”¨dataloaderä¼šé‡æ–°å¯åŠ¨è¿›ç¨‹
                predict_data = torch.empty(len(dataset), dtype=torch.uint8, device=device) # é¢„åˆ†é…å†…å­˜ï¼Œç”¨æ¥å‚¨å­˜é¢„æµ‹ç»“æœ
                for data in tqdm(dataloader, total=len(dataloader), desc='Block Predicting'):
                    batch = data.shape[0]
                    data = data.to(device)
                    outputs = model(data)
                    if outputs.dim() == 1:
                        outputs = outputs.unsqueeze(0)
                    _, predicted = torch.max(outputs, 1)
                    predict_data[idx:idx + batch, ] = predicted
                    idx += batch
                predict_map[background_mask] = predict_data.cpu().numpy() if predict_data.device.type == 'cuda' else predict_data.numpy() # å°†é¢„æµ‹ç»“æœå¡«å…¥å¯¹åº”ä½ç½®
                predict_whole_map[i:i+rows, j:j+cols] = predict_map # å°†é¢„æµ‹ç»“æœå¡«å…¥æ•´ä½“é¢„æµ‹çŸ©é˜µ

                # æ›´æ–°é¢„æµ‹è¿‡ç¨‹ä¸­çš„å›¾åƒ
                block_rgb = utils.label_to_rgb(predict_map, background_value=255)
                global_rgb_vis[i:i+rows, j:j+cols] = block_rgb
                pred_imshow_obj.set_data(global_rgb_vis)
                fig.savefig(out_png, dpi=150)
    img.save_tif(output_path, predict_whole_map, nodata=255) # æœ€ç»ˆä¿å­˜ä¸ºtifæ–‡ä»¶